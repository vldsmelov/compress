# Микросервисный стек контрактного анализа

Набор сервисов на FastAPI и Vite, которые взаимодействуют через HTTP внутри общей Docker-сети и доступны с хоста по `localhost`. Стек включает извлечение данных из договоров, юридическую и экономическую проверку, нарезку документов и административную панель.

## Состав сервисов
- **contract_extractor** — извлечение данных из договора, готовые планы вопросов и проверка SB AI.
- **ai_econom** — экономический анализ договоров.
- **ai_legal** — проверка и подготовка разделов договора.
- **document_slicer** — нарезка документов и проксирование запросов к остальным сервисам.
- **admin-panel** — веб-интерфейс для работы с сервисами.
- **ollama** — LLM-хост для работы всех сервисов.

## Быстрый старт
1. Убедитесь, что Docker установлен.
2. Соберите и запустите все сервисы одним compose-файлом и Dockerfile:

```bash
docker compose up -d --build
```
3. Доступные точки входа с хоста:
   - Контрактный экстрактор: http://localhost:8085
   - Document slicer: http://localhost:8090
   - Admin-panel: http://localhost:8091
   - AI Legal: http://localhost:8092
   - Ollama: http://localhost:11434

Сервисы взаимодействуют друг с другом внутри сети compose по именам контейнеров, при этом конечные точки остаются доступными на `localhost` для разработки и интеграции.

## Структура репозитория
```
services/
  contract_extractor/   # контрактный экстрактор и его зависимости
  ai_econom/            # экономический анализ
  ai_legal/             # юридический анализ
  document_slicer/      # сервис нарезки и маршрутизации запросов
  admin-panel/          # фронтенд панель управления
Dockerfile              # единый multi-stage Dockerfile для всех сервисов
docker-compose.yml      # корневой compose-файл
```

Compose запускает локальный Ollama, а сервисы подключаются к нему по адресу `http://ollama:11434` внутри общей сети. Используйте переменные окружения в `docker-compose.yml`, чтобы выбрать нужную модель или адаптировать таймауты. По умолчанию все сервисы ожидают модель `qwen3:14b` на сервисе `ollama`.

### Выбор модели один раз для всех сервисов

Переменная `OLLAMA_MODEL` задаёт имя модели сразу для contract_extractor, ai_econom и ai_legal. Это позволяет запустить стек на небольшой модели для проверки, а затем переключиться на «боевую» без правок в каждом сервисе:

```bash
# Поднять всё на компактной модели
OLLAMA_MODEL=qwen2:1.5b docker compose up -d --build

# После проверки просто укажите «боевую» модель и перезапустите
OLLAMA_MODEL=qwen3:14b docker compose up -d
```

## Основные эндпоинты контрактного экстрактора
- `GET /healthz` — проверка живости.
- `POST /check` — извлечение данных из текста.
- `POST /qa` — ответы на произвольные вопросы к разделам.
- `POST /qa/docx` — загрузка DOCX и выполнение преднастроенных планов вопросов.
- `POST /qa/sections` — получение уже нарезанных частей договора и выполнение QA-плана с блоком `sb_ai`.

Готовые планы хранятся в `services/contract_extractor/app/assets/qa_plans/`. Пользовательские схемы и контексты можно складывать в `services/contract_extractor/app/assets/users_assets/`.

x-ollama-model: &ollama-model
  OLLAMA_MODEL: ${OLLAMA_MODEL:-qwen3:14b-8k}

services:
  rabbitmq:
    image: rabbitmq:3-management
    container_name: rabbitmq
    ports:
      - "5672:5672"
      - "15672:15672"
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_DEFAULT_USER:-guest}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_DEFAULT_PASS:-guest}
    networks:
      - app-network

  # ollama:
    # image: ollama/ollama:latest
    # container_name: ollama
    # ports:
    #   - "11434:11434"
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]
    # runtime: nvidia
    # environment:
    #   NVIDIA_VISIBLE_DEVICES: ${NVIDIA_VISIBLE_DEVICES:-all}
    #   NVIDIA_DRIVER_CAPABILITIES: ${NVIDIA_DRIVER_CAPABILITIES:-compute,utility}
    #   OLLAMA_GPU_DRIVER: ${OLLAMA_GPU_DRIVER:-cuda}
    #   CUDA_VERSION: ${CUDA_VERSION:-13}
    # volumes:
    #   - ollama_data:/root/.ollama
    # restart: unless-stopped
    # networks:
    #   - app-network

  gateway:
    build:
      context: .
      dockerfile: Dockerfile
      target: gateway
    container_name: gateway
    environment:
      - RABBITMQ_URL=amqp://guest:guest@rabbitmq/
      - DOC_UPLOAD_QUEUE=doc_upload
    command: uvicorn app.main:app --host 0.0.0.0 --port 8099
    ports:
      - "8099:8099"
    depends_on:
      - rabbitmq
    networks:
      - app-network

  contract_extractor:
    build:
      context: .
      dockerfile: Dockerfile
      target: contract_extractor
    container_name: contract_extractor
    environment:
      <<: *ollama-model
      OLLAMA_MODEL: ${OLLAMA_MODEL:-${MODEL:-qwen3:14b-8k}}
      OLLAMA_HOST: http://192.168.3.63:11434/
      MODEL: ${MODEL:-${OLLAMA_MODEL:-qwen3:14b-8k}}
      TEMPERATURE: ${TEMPERATURE:-0.1}
      MAX_TOKENS: ${MAX_TOKENS:-32000}
      NUMERIC_TOLERANCE: ${NUMERIC_TOLERANCE:-0.01}
      USE_LLM: ${USE_LLM:-true}
      API_PORT: ${API_PORT:-8085}
      RABBITMQ_URL: amqp://guest:guest@rabbitmq/
      AGGREGATION_RESULTS_QUEUE: aggregation_results
      CONTRACT_EXTRACTOR_QUEUE: contract_extractor_parts
    command: python -m contract_extractor.app.rabbit_worker
    restart: unless-stopped
    depends_on:
      # - ollama
      - rabbitmq
    networks:
      - app-network

  ai_econom:
    build:
      context: .
      dockerfile: Dockerfile
      target: ai_econom
    container_name: ai_econom
    environment:
      <<: *ollama-model
      OLLAMA_MODEL: ${AI_ECON_OLLAMA_MODEL:-${OLLAMA_MODEL:-qwen3:14b-8k}}
      OLLAMA_HOST: ollama
      OLLAMA_PORT: 11434
      RABBITMQ_URL: amqp://guest:guest@rabbitmq/
      AI_ECONOM_QUEUE: ai_econom_parts
      AGGREGATION_RESULTS_QUEUE: aggregation_results
      SB_QUEUE: sb_queue
    volumes:
      - ./services/budget_service/data:/app/data
    command: python -m app.rabbit_worker
    restart: unless-stopped
    depends_on:
      # - ollama
      - rabbitmq
    networks:
      - app-network

  budget_service:
    build:
      context: .
      dockerfile: Dockerfile
      target: budget_service
    container_name: budget_service
    ports:
      - "10010:10010"
    volumes:
      - ./services/budget_service/data:/app/data
    restart: unless-stopped
    networks:
      - app-network

  ai_legal:
    build:
      context: .
      dockerfile: Dockerfile
      target: ai_legal
    container_name: ai_legal
    environment:
      <<: *ollama-model
      OLLAMA_MODEL: ${AI_LEGAL_MODEL:-${OLLAMA_MODEL:-qwen3:14b-8k}}
      OLLAMA_BASE_URL: http://192.168.3.63:11434
      RABBITMQ_URL: amqp://guest:guest@rabbitmq/
      AI_LEGAL_QUEUE: ai_legal_parts
      AGGREGATION_RESULTS_QUEUE: aggregation_results
    command: python -m app.rabbit_worker
    restart: unless-stopped
    depends_on:
      # - ollama
      - rabbitmq
    networks:
      - app-network

  ai_sb:
    build:
      context: .
      dockerfile: Dockerfile
      target: ai_sb
    container_name: ai_sb
    environment:
      - RABBITMQ_URL=amqp://guest:guest@rabbitmq/
      - SB_QUEUE=sb_queue
      - AGGREGATION_RESULTS_QUEUE=aggregation_results
    command: python main.py
    restart: unless-stopped
    depends_on:
      - rabbitmq
    networks:
      - app-network

  document_slicer:
    build:
      context: .
      dockerfile: Dockerfile
      target: document_slicer
    container_name: document_slicer
    environment:
      - SERVICE_HTTP_TIMEOUT=${SERVICE_HTTP_TIMEOUT:-120}
      - RABBITMQ_URL=amqp://guest:guest@rabbitmq/
      - DOC_UPLOAD_QUEUE=doc_upload
      - AI_LEGAL_QUEUE=ai_legal_parts
      - AI_ECONOM_QUEUE=ai_econom_parts
      - CONTRACT_EXTRACTOR_QUEUE=contract_extractor_parts
      - AGGREGATION_QUEUE=aggregation_tasks
      - DATA_VOLUME_PATH=/data
    volumes:
      - document_data:/data
    command: python -m app.rabbit_worker
    restart: unless-stopped
    depends_on:
      - rabbitmq
    networks:
      - app-network

  aggregator:
    build:
      context: .
      dockerfile: Dockerfile
      target: aggregator
    container_name: aggregator
    environment:
      - RABBITMQ_URL=amqp://guest:guest@rabbitmq/
      - AGGREGATION_QUEUE=aggregation_tasks
      - AGGREGATION_RESULTS_QUEUE=aggregation_results
    command: python main.py
    restart: unless-stopped
    depends_on:
      - rabbitmq
    networks:
      - app-network

  admin-panel:
    build:
      context: .
      dockerfile: Dockerfile
      target: admin-panel
      args:
        VITE_SLICER_API_BASE_URL: http://localhost:8090
        VITE_AI_LEGAL_API_BASE_URL: http://localhost:8092
    container_name: admin-panel
    environment:
      - VITE_SLICER_API_BASE_URL=http://localhost:8090
      - VITE_AI_LEGAL_API_BASE_URL=http://localhost:8092
      - VITE_GATEWAY_URL=http://gateway:8099
    ports:
      - "8091:80"
    restart: unless-stopped
    networks:
      - app-network

volumes:
  document_data:
  ollama_data:

networks:
  app-network:
    external: true